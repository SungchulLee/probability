\documentclass[12pt]{article}%report, article
%\documentstyle[12pt,leqno]{article}

\textwidth=15.5cm \textheight=21.6cm \topmargin=-0.5cm
\oddsidemargin=0.05cm

\newcommand{\bbA}{{\bf A}}
\newcommand{\bba}{{\bf a}}
\newcommand{\bbB}{{\bf B}}
\newcommand{\bbb}{{\bf b}}
\newcommand{\bbC}{{\bf C}}
\newcommand{\bbc}{{\bf c}}
\newcommand{\bbD}{{\bf D}}
\newcommand{\bbd}{{\bf d}}
\newcommand{\bbE}{{\bf E}}
\newcommand{\bbe}{{\bf e}}
\newcommand{\bbI}{{\bf I}}
\newcommand{\bbi}{{\bf i}}
\newcommand{\bbJ}{{\bf J}}
\newcommand{\bbj}{{\bf j}}
\newcommand{\bbK}{{\bf K}}
\newcommand{\bbk}{{\bf k}}
\newcommand{\bbP}{{\bf P}}
\newcommand{\bbp}{{\bf p}}
\newcommand{\bbQ}{{\bf Q}}
\newcommand{\bbq}{{\bf q}}
\newcommand{\bbT}{{\bf T}}
\newcommand{\bbt}{{\bf t}}
\newcommand{\bbU}{{\bf U}}
\newcommand{\bbu}{{\bf u}}
\newcommand{\bbV}{{\bf V}}
\newcommand{\bbv}{{\bf v}}
\newcommand{\bbW}{{\bf W}}
\newcommand{\bbw}{{\bf w}}
\newcommand{\bbX}{{\bf X}}
\newcommand{\bbx}{{\bf x}}
\newcommand{\X}{{\cal X}}
\newcommand{\bbY}{{\bf Y}}
\newcommand{\bby}{{\bf y}}
\newcommand{\bbZ}{{\bf Z}}
\newcommand{\bbz}{{\bf z}}
\newcommand{\0}{{\bf 0}}
\newcommand{\R}{{\bf R}}
\newcommand{\txi}{\bar{\xi}}
\def\Comment#1{ \marginpar{$\bullet$\quad{\tiny #1}}}


\usepackage{graphics,graphicx,amsmath,float,color,subfigure,enumerate,booktabs}
%\usepackage[tiling]{pst-fill}
\usepackage[dvips]{xy}
\usepackage{tikz}
\usetikzlibrary{matrix}
\input{rgb}
\xyoption{all}


\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}


\begin{document}
%controls the margin
\baselineskip=6.0mm








%Ignore some parts of statements
\newcommand{\ignore}[1]{}{}





%Equation numbers contain section number
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}





%Activate this if I want to display eq number only
\newcommand{\lbl}{\label}

%Activate this if I want to display eq number and text number, too
%\newcommand{\lbl}[1]{\hspace{1cm} \underline{({#1})} \label{#1}}





%Call this eq numbers in text
\newcommand{\eq}[1]{$(\ref{#1})$}


\newcommand{\f}{\frac}    


%Short for Greek letters
\newcommand{\al}{\alpha}                         %\al=\al
\newcommand{\bt}{\beta}                          %\bt=w
\newcommand{\ga}{\gamma}                         %\ga=\gamma
\newcommand{\Ga}{\Gamma}                         %\Ga=\Gamma
\newcommand{\de}{\delta}                         %\de=\delta
\newcommand{\De}{\Delta}                         %\De=\Delta
\newcommand{\ep}{\epsilon}                       %\ep=\epilon
\newcommand{\ve}{\varepsilon}                    %\ve=\varepsilon
\newcommand{\la}{\lambda}                        %\la=\lambda
\newcommand{\La}{\Lambda}                        %\La=\Lambda
\newcommand{\ro}{\rho}                           %\ro=\rho
\newcommand{\ta}{\tau}                           %\ta=tau
%\newcommand{\th}{\theta}                         %\th=\theta
\newcommand{\si}{\sigma}                         %\si=\sigma
\newcommand{\Si}{\Sigma}                         %\si=\sigma
\newcommand{\om}{\omega}                           %\ro=\rho
\newcommand{\Om}{\Omega}                           %\ta=tau





%Short for equation array and for equations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\be}{\begin{equation}}               %\be=\begin{equation}
\newcommand{\ee}{\end{equation}}                 %\ee=\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\bea}{\begin{eqnarray}}              %\bea=\begin{eqnarray}
\newcommand{\eea}{\end{eqnarray}}                %\eea=\end{eqnarray}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\bean}{\begin{eqnarray*}}            %\beq=\begin{eqnarray*}
\newcommand{\eean}{\end{eqnarray*}}              %\eeq=\end{eqnarray*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newcommand{\beq}{\begin{eqnarray*}}            %\beq=\begin{eqnarray*}
%\newcommand{\eeq}{\end{eqnarray*}}              %\eeq=\end{eqnarray*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ba}{\begin{array}}                  %\ba=\begin{array}
\newcommand{\ea}{\end{array}}                    %\ea=\end{array}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\nn}{\nonumber}                      %\nn=\nonumber
\newcommand{\mb}{\mbox}                          %\mb=\mbox





%\newcommand{\ra}{\rightarrow}                    %\ra=\rightarrow
\newcommand{\Ra}{\Rightarrow}                    %\ra=\rightarrow
\newcommand{\ua}{\uparrow}   
\newcommand{\da}{\downarrow}   
\newcommand{\Lra}{\Leftrightarrow}          %\llra=\longleftrightarrow
\newcommand{\llra}{\longleftrightarrow}          %\llra=\longleftrightarrow

\newcommand{\stac}{\stackrel}                    %\stac=\stackrel
\newcommand{\noin}{\noindent}                    %\noin=\noindent

%Symbol for the end of the proof
\newcommand{\qed}{\nobreak\quad\vrule width6pt depth3pt height10pt}

\newcommand{\ngi}{n \ra \infty}

%heading
%\pagestyle{myheadings} \markright{Rooted edges of a minimal directed spanning tree on random points}
\pagestyle{myheadings} \markright{[Homework] Distributions related to normal distribution}

\thispagestyle{plain}


\begin{center}
{\Large\bf [Homework] Distributions related to normal distribution} 
\end{center}






\begin{enumerate}




\item
Compute the PDF of $Y=\log X$, where $X\sim Exp(1)$.
\\
{\color{blue}{\bf Sol.}}
$$F_Y (y) = P\{Y \le y\} = P\{logX \le y\} = P\{X \le e^y\} = F_X(e^y)$$
Hence, on differentiation, we obtain
$$f_Y (y) = F'_Y (y) = f_X(e^y)\cdot e^y = e^{y-e^y}$$


\item
Let $Y_1=X_1+X_2$ and let $Y_2=e^{X_1}$, where $X_i$ are iid $X\sim Exp(1)$.
\begin{enumerate}
\item
Identify the distribution of $Y_1$ and report its mean and variance.
\\
{\color{blue}{\bf Sol.}}
Since
$$X+Y \sim \Ga(\al=2, \la=1)$$
$$EY_1=\f{\al}{\la}=2$$
$$VarY_1=\f{\al}{\la^2}=2$$

\item
Find the joint PDF $f(y_1,y_2)$ of $Y_1$ and $Y_2$.
\\
{\color{blue}{\bf Sol.}}
$$J=\f{\partial(Y_1,Y_2)}{\partial(X_1,X_2)}=-e^{x_1}$$
\bea
f_{Y_1,Y_2}(y_1,y_2)
&=&f_{X_1}(x)f_{X_2}(x_2)\cdot |J|^{-1} \nn\\
&=&\la^2e^{-\la(x_1+x_2)}\cdot \f{1}{e^{x_1}} \nn\\
&=&\la^2e^{-\la y_1}\cdot \f{1}{y_2} \nn\\
&=&e^{-y_1}\cdot \f{1}{y_2} \nn
\eea

\end{enumerate}





\item
Let $X$, $Y$, and $Z$ be iid $Exp(1)$.
Derive the joint distribution of $U=X+Y$, $V=Y+Z$, $W=X+Z$.
\\
{\color{blue}{\bf Sol.}}
$$f_X(x)=f_Y(y)=f_Z(z)=e^{-x}$$

$$x=\f{u+v-w}{2},y=\f{u-v+w}{2},x=\f{-u+v+w}{2}$$
$$J=\f{\partial(u,v,w)}{\partial(x,y,z)}=2$$
\bea
f_{U,V,W}(u,v,w)
&=&f_X(x)f_Y(y)f_Z(z)\cdot |J|^{-1} \nn\\
&=&e^{-x}\cdot e^{-y}\cdot e^{-z}\f{1}{2} \nn\\
&=&\f{1}{2}e^{-\f{u+v+w}{2}}\nn
\eea

\item
Let $X_i$ be iid $Exp(1)$. Compute
\begin{enumerate}
\item
$P(\min\{X_1,\cdots,X_5\} \le a)$.
\\
{\color{blue}{\bf Sol.}}
\bea
P(\min\{X_1,\cdots,X_5\} \le a)
&=&1-P(\min\{X_1,\cdots,X_5\} > a)\nn\\
&=&1-P(X_1>a)\cdots P(X_5>a) \nn\\
&=&1-e^{-5\la a}=1-e^{-5 a}\nn
\eea


\item
$P(\max\{X_1,\cdots,X_5\} \le a)$.
\\
{\color{blue}{\bf Sol.}}
\bea
P(\max\{X_1,\cdots,X_5\} \le a)
&=&P(X_1\le a,\cdots,X_5\le a)\nn\\
&=&P(X_1\le a)\cdots P(X_5\le a) \nn\\
&=&(1-e^{-\la a})^5=(1-e^{-a})^5\nn
\eea



\end{enumerate}

\item
Let $U_i$ be iid $U(0,1)$.
Let $X_n$ be the number of $U_i$, $1\le i\le n$ with $U_i\le \f{1}{n}$ 
and $Y_n$ be the number of $U_i$, $1\le i\le n$ with $\f{1}{n}\le U_i\le \f{2}{n}$.
As $n\rightarrow\infty$ find the joint PMF of $X_n$ and $Y_n$.
\\
{\color{blue}{\bf Sol.}}
$$P(X_n=x)={n \choose x}(\f{1}{n})^x(1-\f{1}{n})^{n-x}$$
$$P(Y_n=y|X_n=x)={n-x \choose y}(\f{1}{n-1})^y(1-\f{1}{n-1})^{n-x-y}$$
\bea
P(X_n=x,Y_n=y)
&=&P(Y_n=y|X_n=x)\cdot P(X_n=x)\nn\\
&=&\f{(n-x)!}{(n-x-y)!y!}\cdot\f{n!}{(n-x)!x!}(\f{1}{n})^x(1-\f{1}{n})^{n-x}\cdot (\f{1}{n-1})^y(1-\f{1}{n-1})^{n-x-y}\nn\\
&=&\f{n!}{(n-x-y)!y!x!}\f{1}{n^x}\f{1}{(n-1)^y}(1-\f{1}{n})^n(\f{n-1}{n})^x(1-\f{1}{n-1})^{n-1}\nn\\
& & \cdot (\f{n-2}{n-1})^{-x-y+1} \nn
\eea
joint PMF of $X_n,Y_n$ as $n \rightarrow \infty$
$$f_{X_n,Y_n}(x,y)=\f{1}{x!y!}e^{-2}$$




\item  
The joint density function of $X$ and $Y$ is given by
$$
f(x,y)=\left\{\ba{ll}
2e^{-x}e^{-2y}&\mb{for}\ 0<x<\infty, 0<y<\infty,\\
0&\mb{otherwise.}
\ea\right..
$$
Find the PDF of $\f{X}{Y}$.  
\\
{\color{blue}{\bf Sol.}}
\bea
F_{\f{X}{Y}}(a)
&=&P(\f{X}{Y} \le a)\nn\\
&=&P(X \le aY) \nn\\
&=&\int_0^{\infty}\int_0^{ay}2e^{-x}e^{-2y} dx dy\nn\\
&=&1-\f{2}{2+a}\nn
\eea

$$f_{\f{X}{Y}}(a)=\f{d}{da} F_{\f{X}{Y}}(a)=\f{2}{(2+a)^2}$$


\item
Successive weekly sales, in units of one thousand dollars, have a bivariate normal distribution with common mean 40, common standard deviation 6, and correlation 0.6.
\begin{enumerate}
\item Find the probability that the total of the next 2 weeks' sales exceeds 90.
\\
{\color{blue}{\bf Sol.}}
$$X_1,X_2 \sim N(40,6^2)$$
$$\rho=\f{Cov(X,Y)}{\sqrt{VarX\cdot VarY}}$$
Therefore, $Cov(X_1,X_2)=21.6$
$$X_1+X_2 \sim Normal ~~ (\mb{Why??})$$
$$E(X_1+X_2)=EX_1+EX_2=80$$
$$Var(X_1+X_2)=VarX_1+VarX_2+2Cov(X_1,X_2)=115.2$$ 
\bea
P(X_1+X_2>90)
&=&P(\f{(X_1+X_2)-80}{\sqrt{115.2}}>\f{90-80}{\sqrt{115.2}})\nn\\
&=&P(Z>\f{10}{\sqrt{115.2}}) \nn\\
&=&1-\Phi(\f{10}{\sqrt{115.2}})\nn
\eea

\item If the correlation were 0.2 rather than 0.6, do you think that this would increase or decrease the answer to (a)? Explain your reasoning.
\\
{\color{blue}{\bf Sol.}}


\item Repeat (a) with the correlation is 0.2 to check your intuition on (b).
\\
{\color{blue}{\bf Sol.}}

$Cov(X_1,X_2)=7.2$
$$E(X_1+X_2)=EX_1+EX_2=80$$
$$Var(X_1+X_2)=VarX_1+VarX_2+2Cov(X_1,X_2)=86.4$$ 
\bea
P(X_1+X_2>90)
&=&P(\f{(X_1+X_2)-80}{\sqrt{86.4}}>\f{90-80}{\sqrt{86.4}})\nn\\
&=&P(Z>\f{10}{\sqrt{86.4}}) \nn\\
&=&1-\Phi(\f{10}{\sqrt{86.4}})\nn
\eea

\end{enumerate}














\item
The mean and standard deviation of the midterm scores of the probability corse are 71 and 12
and
the mean and standard deviation of the final are 70 and 11.
The correlation $\rho$ is 0.6.
Suppose the joint distribution of the midterm and final scores is the bivariate normal.
\begin{enumerate}
\item Predict the final score for someone who got 83 on midterm.
\\
{\color{blue}{\bf Sol.}}



\item Predict the midterm score for someone who got 76.6 on final.
\\
{\color{blue}{\bf Sol.}}



\item Predict the final percentile for someone who got 31st percentile on midterm.
\\
{\color{blue}{\bf Sol.}}





\item Predict the midterm percentile for someone who got 38th percentile on final.
\\
{\color{blue}{\bf Sol.}}




\end{enumerate}




\item
The random variables $X$ and $Y$ are described by a joint PDF of the
form
$$f_{X,Y} (x, y) = ce^{-8x^2-6xy-18y^2}$$
Find the means, variances, and the correlation coefficient of X and Y. Also, and the
value of the constant $c$.
\\
{\color{blue}{\bf Sol.}}
Since $$\int_{\infty}^{\infty}\int_{\infty}^{\infty}f_{X,Y} (x, y)dx dy=1 $$
\bea
\int_{\infty}^{\infty}\int_{\infty}^{\infty}f_{X,Y} (x, y)dx dy
&=&\int_{\infty}^{\infty}ce^{-\f{135}{8}y^2}\int_{\infty}^{\infty}e^{-8(x+\f{3}{8}y)^2}dx dy\nn\\
&=&\int_{\infty}^{\infty}ce^{-\f{135}{8}y^2}\int_{\infty}^{\infty}\f{1}{4}e^{-\f{1}{2}u^2}du dy ~~ (u=4(x+\f{3}{8}y) )\nn\\
&=&\int_{\infty}^{\infty}ce^{-\f{135}{8}y^2}\f{1}{4} \sqrt{2 \pi} dy\nn\\
&=&\f{ \sqrt{2 \pi} c}{4}\int_{\infty}^{\infty}e^{-\f{135}{8}y^2}dy~~ (v=\f{\sqrt{135}}{2}y)\nn\\
&=&\f{ \sqrt{2 \pi} c}{2\sqrt{135}}\int_{\infty}^{\infty}e^{-\f{1}{2}v^2}dv\nn\\
&=&\f{\pi}{\sqrt{135}}\nn\\
\eea
Therefore $c=\f{\sqrt{135}}{\pi}$
\\
Similarly, $$\rho=-\f{1}{4}, EX=0, VarX=\f{9}{135} , EY=0, VarY=\f{4}{135} $$
(Why? Explain!Find bivariate normal distribution.)


\item
Let $X_1$ and $X_2$ be independent standard normal random variables.
Define the random variables $Y_1$ and $Y_2$ by
$$Y_1 = 2X_1 + X_2,\quad Y_2 = X_1 - X_2$$
Find $E[Y_1]$, $E[Y_2]$, $Var(Y_1)$, $Var(Y_2)$ $Cov(Y_1, Y_2)$, and the joint PDF $f_{Y_1,Y_2}$.
\\
{\color{blue}{\bf Sol.}}
Since $X_1,X_2 \sim N(0, 1^2)$
$$EY_1=2EX_1+EX_2=0,EY_2=0$$
$$VarY_1=4VarX_1+VarX_2=5,VarY_2=VarX_1+VarX_2=2$$
$$Cov(Y_1,Y_2)=Cov(2X_1+X_2,X_1-X_2)=1$$
$$J=\f{\partial(Y_1,Y_2)}{\partial(X_1,X_2)}=-3 ~ (\mb{why?})$$
Since $x_1=\f{y_1+y_2}{3},x_2=\f{y_1-2y_2}{3}$
\bea
f_{Y_1,Y_2}(y_1,y_2)
&=&f_{X_1,X_2}(x_1,x_2)\cdot |J|^{-1} \nn\\
&=&\f{1}{\sqrt{2\pi}}e^{-\f{x_1^2}{2}}\cdot \f{1}{\sqrt{2\pi}}e^{-\f{x_2^2}{2}}\cdot \f{1}{3} \nn\\
&=&\f{1}{6 \pi }e^{-\f{1}{2}\{(\f{y_1+y_2}{3})^2+(\f{y_1-2y_2}{3})^2\}}\nn
\eea
\end{enumerate}


\begin{center}
{\Large\bf [Extra]} 
\end{center}






\begin{enumerate}








\item
Suppose that $X$ and $Y$ are independent normal random variables with
the same variance. Show that $X-Y$ and $X +Y$ are independent.














\end{enumerate}


\end{document}
